<!DOCTYPE html><!--Mobile_v7.0-->
<html lang="es">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes, maximum-scale=2.0, minimum-scale=0.5">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <title>Soundins - Dither & NS Benchmarker (Mobile)</title>
  <link rel="icon" type="image/x-icon" href="favicon.ico">
  <style>
    /* Estilos omitidos para brevedad, son idénticos al original */
  </style>
</head>
<body>
  <div id="header-container">
    <div id="header-background"></div>
    <button id="fullscreen-btn" title="Maximizar pantalla">⛶</button>
    <span id="readme-link" onclick="toggleLanguageMenu()">Readme</span>
    <div id="language-menu">
      <button onclick="openInstructions('en')">English</button>
      <button onclick="openInstructions('es')">Español</button>
    </div>
    <a href="http://www.soundins.com.ar">
      <img src="Soundins.png" id="logo" alt="Logo de Soundins">
    </a>
    <h1>Dither & NS Benchmark Tool</h1>
    <div id="version-text">v7.0Mobile</div>
    <div id="mode-toggle-container">
      <button id="mode-toggle-btn">
        <img id="mode-icon" src="dark_mode.png" alt="Dark Mode">
      </button>
    </div>
  </div>
  <div id="rotation-message">
    <div id="rotation-text">Por favor, rote el dispositivo a la posición horizontal<br><br>Please rotate the device to horizontal position</div>
  </div>
  <div id="main-content">
    <div id="progress-container">
      <div id="progress-bar">
        <div id="progress-fill"></div>
      </div>
      <div id="progress-text">Loading Audio Files</div>
    </div>
    <div id="main-row">
      <div class="source-group">
        <span class="source-label">Source</span>
        <div class="source-btn active" id="source-Sine">Sine</div>
        <div class="source-btn" id="source-flaute">Instrument</div>
      </div>
      <div class="rect" id="rect-24bits">24 bits</div>
      <div class="rect" id="rect-main">16 bits No Dither</div>
      <button id="toggle-btn">997Hz</button>
      <button id="stop-btn"></button>
    </div>
    <div id="table-container">
      <table>
        <thead>
          <tr>
            <th>Izotope</th>
            <th>Izotope</th>
            <th>FabFilter</th>
            <th>Waves</th>
            <th>Waves</th>
            <th>Reaper</th>
            <th>Ableton</th>
            <th>Avid</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td><div class="rect" id="rect-1">Ozone 11<br>Dither: Low<br>NS: Off</div></td>
            <td><div class="rect" id="rect-2">Ozone 11<br>Dither: Strong<br>NS: Off</div></td>
            <td><div class="rect" id="rect-3">Pro L2<br>Dither: On<br>NS: Off</div></td>
            <td><div class="rect" id="rect-4">L2<br>Dither: T1<br>NS: Off</div></td>
            <td><div class="rect" id="rect-5">L2<br>Dither: T2<br>NS: Off</div></td>
            <td><div class="rect" id="rect-8">Reaper<br>Dither: On<br>NS: Off</div></td>
            <td><div class="rect" id="rect-9">Live<br>Dither: TPDF<br>NS: Off</div></td>
            <td><div class="rect" id="rect-10">ProTools (Maxim)<br>Dither: On<br>NS: Off</div></td>
          </tr>
          <tr>
            <td><div class="rect" id="rect-31">Ozone 11<br>Dither: Low<br>NS: Max</div></td>
            <td><div class="rect" id="rect-32">Ozone 11<br>Dither: Strong<br>NS: Max</div></td>
            <td><div class="rect" id="rect-33">Pro L2<br>Dither: On<br>NS: Weighted</div></td>
            <td><div class="rect" id="rect-34">L2<br>Dither: T1<br>NS: Ultra</div></td>
            <td><div class="rect" id="rect-35">L2<br>Dither: T2<br>NS: Ultra</div></td>
            <td><div class="rect" id="rect-38">Reaper<br>Dither: On<br>NS: On</div></td>
            <td><div class="rect" id="rect-39">Live<br>Dither: TPDF<br>NS: POWr3</div></td>
            <td><div class="rect" id="rect-40">ProTools (Dither)<br>Dither: On<br>NS: Type 3</div></td>
          </tr>
        </tbody>
      </table>
    </div>
    <div id="spectrum-container" class="minimized">
      <div id="spectrum-header">
        <span id="spectrum-title">Spectrum Analyzer</span>
        <div id="spectrum-buttons">
          <button id="minimize-btn"></button>
          <button id="maximize-btn"></button>
        </div>
      </div>
      <canvas id="spectrumCanvas"></canvas>
    </div>
  </div>

  <script>
    const audioMapping = {
      // Mapeo de audio omitido para brevedad, es idéntico al original
    };

    let isToggleEnabled = true;
    let currentActiveRect = null;
    let lastActiveRect = null;
    let currentSource = "Sine";
    const audioPlayers = {};
    let preloadPromise = null;
    let isIOS = /iPad|iPhone|iPod/.test(navigator.userAgent) && !window.MSStream;
    let hasProgressBarBeenShown = false;

    const sourceSine = document.getElementById("source-Sine");
    const sourceFlaute = document.getElementById("source-flaute");
    const toggleBtn = document.getElementById("toggle-btn");
    const stopBtn = document.getElementById("stop-btn");
    const progressContainer = document.getElementById("progress-container");
    const progressFill = document.getElementById("progress-fill");

    const rectsToLoad = [
      "rect-24bits", "rect-main",
      "rect-1", "rect-2", "rect-3", "rect-4", "rect-5", "rect-8", "rect-9", "rect-10",
      "rect-31", "rect-32", "rect-33", "rect-34", "rect-35", "rect-38", "rect-39", "rect-40"
    ];

    let audioContext = null;
    let analyser = null;
    let sourceNode = null;
    let gainNode = null;
    let mediaSource = null; // Para iOS, se recreará por cada reproducción
    const canvas = document.getElementById("spectrumCanvas");
    const ctx = canvas.getContext("2d");
    canvas.width = 250;
    canvas.height = 80;
    let smoothedData = null;
    const smoothingWindow = 50;
    let dataHistory = [];

    function initializeAudioContext() {
      try {
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        analyser = audioContext.createAnalyser();
        analyser.fftSize = 16384;
        analyser.smoothingTimeConstant = 0.1;
        analyser.minDecibels = -110;
        analyser.maxDecibels = -60;
        gainNode = audioContext.createGain();
        gainNode.gain.setValueAtTime(isIOS ? 2.0 : 1.0, audioContext.currentTime);
        analyser.connect(gainNode);
        gainNode.connect(audioContext.destination);
        smoothedData = new Float32Array(analyser.frequencyBinCount);
        console.log("AudioContext initialized. State:", audioContext.state);
        resumeAudioContext();
        if (!window.isDrawing) {
          window.isDrawing = true;
          drawSpectrum();
        }
      } catch (e) {
        console.error("Error initializing AudioContext:", e);
      }
    }

    async function resumeAudioContext() {
      if (audioContext && audioContext.state === 'suspended') {
        try {
          await audioContext.resume();
          console.log("AudioContext resumed. State:", audioContext.state);
        } catch (e) {
          console.error("Error resuming AudioContext:", e);
        }
      }
    }

    function drawSpectrum() {
      if (!analyser) {
        console.error("Analyser not defined.");
        return;
      }

      const bufferLength = analyser.frequencyBinCount;
      const dataArray = new Uint8Array(bufferLength);
      analyser.getByteFrequencyData(dataArray);

      dataHistory.push(new Uint8Array(dataArray));
      if (dataHistory.length > smoothingWindow) {
        dataHistory.shift();
      }

      for (let i = 0; i < bufferLength; i++) {
        let sum = 0;
        for (let j = 0; j < dataHistory.length; j++) {
          sum += dataHistory[j][i];
        }
        smoothedData[i] = sum / dataHistory.length;
      }

      ctx.fillStyle = "black";
      ctx.fillRect(0, 0, canvas.width, canvas.height);

      ctx.lineWidth = 2;
      ctx.strokeStyle = "rgb(0, 255, 0)";
      ctx.beginPath();

      const sampleRate = audioContext.sampleRate;
      const freqMax = sampleRate / 2;
      const freqStep = freqMax / bufferLength;

      const minFreq = 20;
      const maxFreq = 20000;
      const logMin = Math.log10(minFreq);
      const logMax = Math.log10(maxFreq);
      const logRange = logMax - logMin;

      let hasData = false;
      ctx.moveTo(0, canvas.height);

      for (let i = 0; i < bufferLength; i++) {
        const freq = i * freqStep;
        if (freq < minFreq || freq > maxFreq) continue;

        const logFreq = Math.log10(freq);
        const x = canvas.width * (logFreq - logMin) / logRange;
        const value = smoothedData[i] / 255;
        const y = canvas.height * (1 - value);

        if (smoothedData[i] > 0) hasData = true;
        ctx.lineTo(x, y);
      }

      ctx.stroke();
      console.log("Spectrum drawn. Data present:", hasData);

      requestAnimationFrame(drawSpectrum);
    }

    // Funciones de UI omitidas para brevedad, son idénticas al original

    async function preloadAllAudio() {
      const totalFiles = Object.values(audioMapping).reduce((sum, sources) => sum + Object.values(sources).reduce((subSum, states) => subSum + Object.keys(states).length, 0), 0);
      let loadedFiles = 0;

      const loadPromises = [];
      for (const rectId in audioMapping) {
        audioPlayers[rectId] = {};
        for (const source in audioMapping[rectId]) {
          audioPlayers[rectId][source] = {};
          for (const state in audioMapping[rectId][source]) {
            const url = audioMapping[rectId][source][state];
            loadPromises.push(
              fetch(url)
                .then(response => {
                  if (!response.ok) throw new Error(`Error fetching ${url}: ${response.statusText}`);
                  return response.arrayBuffer();
                })
                .then(arrayBuffer => {
                  audioPlayers[rectId][source][state] = { buffer: arrayBuffer };
                  loadedFiles++;
                  const progressPercentage = (loadedFiles / totalFiles) * 100;
                  progressFill.style.width = `${progressPercentage}%`;
                  console.log(`Loaded ${url}`);
                })
                .catch(error => {
                  console.error(`Error preloading ${url}:`, error);
                  loadedFiles++;
                  const progressPercentage = (loadedFiles / totalFiles) * 100;
                  progressFill.style.width = `${progressPercentage}%`;
                })
            );
          }
        }
      }

      await Promise.all(loadPromises);
      setTimeout(() => {
        progressContainer.style.display = "none";
      }, 200);
    }

    async function playAudioFromMemory(audioData, rect) {
      if (!audioContext || !analyser || !gainNode) {
        console.log("Reinitializing AudioContext...");
        initializeAudioContext();
      }

      await resumeAudioContext();
      stopAudio();

      if (isIOS) {
        const blob = new Blob([audioData], { type: "audio/flac" });
        const audioURL = URL.createObjectURL(blob);
        const iosAudio = document.getElementById("ios-audio");

        iosAudio.src = audioURL;
        iosAudio.load();

        // Crear un nuevo MediaElementSource para cada reproducción
        mediaSource = audioContext.createMediaElementSource(iosAudio);
        mediaSource.connect(analyser);

        iosAudio.play().then(() => {
          console.log("iOS audio playing.");
          iosAudio.onended = () => {
            if (rect) rect.classList.remove("green");
            stopAudio();
          };
        }).catch(error => {
          console.error("iOS audio playback failed:", error);
          if (rect) rect.classList.remove("green");
        });

        return;
      }

      // Para Android
      try {
        const audioBuffer = await audioContext.decodeAudioData(audioData.slice(0));
        sourceNode = audioContext.createBufferSource();
        sourceNode.buffer = audioBuffer;
        sourceNode.connect(analyser);
        sourceNode.start();
        sourceNode.onended = () => {
          if (rect) rect.classList.remove("green");
          stopAudio();
        };
      } catch (e) {
        console.error("Error decoding or playing audio:", e);
        if (rect) rect.classList.remove("green");
      }
    }

    function stopAudio() {
      if (isIOS) {
        const iosAudio = document.getElementById("ios-audio");
        if (iosAudio) {
          iosAudio.pause();
          iosAudio.src = "";
          console.log("iOS audio stopped.");
        }
        if (mediaSource) {
          mediaSource.disconnect();
          mediaSource = null;
          console.log("MediaElementSource disconnected.");
        }
      }
      if (sourceNode) {
        try {
          sourceNode.stop();
          console.log("SourceNode stopped.");
        } catch (e) {
          console.log("SourceNode already stopped:", e);
        }
        sourceNode.disconnect();
        sourceNode = null;
      }
      ctx.fillStyle = "black";
      ctx.fillRect(0, 0, canvas.width, canvas.height);
      dataHistory = [];
      console.log("Audio resources cleared.");
    }

    function stopAllAudio() {
      stopAudio();
      document.querySelectorAll(".rect.green").forEach(rect => rect.classList.remove("green"));
      currentActiveRect = null;
      console.log("All audio stopped.");
    }

    async function playAudio(rect) {
      if (!audioContext) {
        console.log("Initializing AudioContext for playback...");
        initializeAudioContext();
      }
      await resumeAudioContext();
      const rectId = rect.id;
      const state = rectId === "rect-24bits" && currentSource === "Sine" ? "NA" : (isToggleEnabled ? "997(act)" : "997(no)");
      const audioData = audioPlayers[rectId]?.[currentSource]?.[currentSource === "Sine" ? state : "NA"]?.buffer;
      if (audioData) {
        stopAudio();
        rect.classList.add("green");
        currentActiveRect = rect;
        console.log(`Playing audio for ${rectId}, source: ${currentSource}, state: ${state}`);
        await playAudioFromMemory(audioData, rect);
      } else {
        console.error(`No audio found for ${rectId}, source: ${currentSource}, state: ${state}`);
      }
    }

    // Resto de funciones de UI y eventos omitidas para brevedad, son idénticas al original

    document.addEventListener('touchstart', function initAudioOnTouch() {
      if (!audioContext) {
        initializeAudioContext();
      }
    }, { once: true });

    preloadPromise = preloadAllAudio();
  </script>

  <audio id="ios-audio" style="display: none;"></audio>
</body>
</html>